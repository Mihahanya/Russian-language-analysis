{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole text size: 38359680 so used 38359680\n",
      "Alphabet length: 213\n",
      "Alphabet: \u0001\u0007\u0019 !\"#%&'()*,-./0123456789:;<=>?@[]^_`abcdefghijklmnopqrstuvwxyz{|}~§«°·»½¾ßàáâäçèéêëíîïòóôöùúûüýÿœ̀́άέήίαβγδεηθικλμνοπρςστυφψωόύώϑабвгдежзийклмнопрстуфхцчшщъыьэюяёєіїљќѣἀἁἃἄἐἔἡἱἴἷὁὄὐὑὰὴὶὸᾶῆ῎ῖῦῶῷ‑–—’“”„…€№⟨⟩养酻셻�\n"
     ]
    }
   ],
   "source": [
    "from data_base import *\n",
    "\n",
    "#data = DataBase(summary=True, max_size=3*10**6)\n",
    "#data = DataBase(summary=True, max_size=200000)\n",
    "data = DataBase(summary=True, max_size=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words: 255586\n",
      "['александр', 'блок', 'стихотворения', 'не', 'вошедшие', 'в', 'основное', 'собрание', 'отроческие', 'стихи']\n",
      "[76763, 234055, 253496, 78455, 32265, 164302, 112367, 56914, 115088, 217509]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "words_sequ = re.findall(r'[А-я]+', data.whole_text)\n",
    "words_to_ids = {v: i for i, v in enumerate(set(words_sequ))}\n",
    "ids_to_words = {i: v for i, v in enumerate(set(words_sequ))}\n",
    "words_sequ_ids = [words_to_ids[word] for word in words_sequ]\n",
    "\n",
    "count_w = len(words_to_ids)\n",
    "\n",
    "print('unique words:', count_w)\n",
    "print(words_sequ[:10])\n",
    "print(words_sequ_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'words_data = [lil_matrix((radius*2, count_w), dtype=np.int16) for _ in range(count_w)]\\n\\nfor i in tqdm(range(len(words_sequ_ids))):\\n\\tfr, to = max(0, i - radius), min(len(words_sequ_ids) - 1, i + radius)\\n\\n\\tfor ii, v in enumerate(words_sequ_ids[fr:i][::-1]):\\n\\t\\twords_data[words_sequ_ids[i]][radius - ii - 1, v] += 1\\n\\n\\tfor ii, v in enumerate(words_sequ_ids[i + 1:to + 1]):\\n\\t\\twords_data[words_sequ_ids[i]][radius + ii, v] += 1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\"\"\"import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from numba import njit, jit, prange\n",
    "\n",
    "#@jit(parallel=True)\n",
    "def get_word_data():\n",
    "\tradius = 5\n",
    "\n",
    "\twords_data = [csr_matrix((radius*2, count_w), dtype=np.int16) for _ in range(count_w)]\n",
    "\t#words_data = {}\n",
    "\n",
    "\tfor i in prange(len(words_sequ_ids)):\n",
    "\t\tfr, to = max(0, i-radius), min(len(words_sequ_ids)-1, i+radius)\n",
    "\t\t#env = words_sequ_ids[fr:i] + words_sequ_ids[i+1:to+1]\n",
    "\t\t\n",
    "\t\tadd = csr_matrix((radius*2, count_w), dtype=np.int16)\n",
    "\t\tfor ii, v in enumerate(words_sequ_ids[fr:i][::-1]):\n",
    "\t\t\tadd[radius-ii-1, v] = 1\n",
    "\n",
    "\t\tfor ii, v in enumerate(words_sequ_ids[i+1:to+1]):\n",
    "\t\t\tadd[radius+ii, v] = 1\n",
    "\t\t\n",
    "\t\twords_data[words_sequ_ids[i]] += add\n",
    "\n",
    "\treturn words_data\n",
    "\n",
    "words_data = get_word_data()\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse.lil import lil_matrix\n",
    "\n",
    "radius = 5\n",
    "\n",
    "\"\"\"words_data = [lil_matrix((radius*2, count_w), dtype=np.int16) for _ in range(count_w)]\n",
    "\n",
    "for i in tqdm(range(len(words_sequ_ids))):\n",
    "\tfr, to = max(0, i - radius), min(len(words_sequ_ids) - 1, i + radius)\n",
    "\n",
    "\tfor ii, v in enumerate(words_sequ_ids[fr:i][::-1]):\n",
    "\t\twords_data[words_sequ_ids[i]][radius - ii - 1, v] += 1\n",
    "\n",
    "\tfor ii, v in enumerate(words_sequ_ids[i + 1:to + 1]):\n",
    "\t\twords_data[words_sequ_ids[i]][radius + ii, v] += 1\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"with open('words_data.pkl', 'wb') as file: \\n    pickle.dump(words_data, file) \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\"\"\"with open('words_data.pkl', 'wb') as file: \n",
    "    pickle.dump(words_data, file) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CA81~1\\AppData\\Local\\Temp/ipykernel_21220/2125211492.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'words_data.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mwords_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\PROGRAMS\\python39\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('words_data.pkl', 'rb') as file: \n",
    "    words_data = pickle.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('нанимаем', 1)]\n",
      "[('полушутовском', 1)]\n",
      "[('глеба', 1)]\n",
      "[('покушаете', 1)]\n",
      "[('удалось', 1)]\n",
      "[('палубах', 1)]\n",
      "[('собачек', 1)]\n",
      "[('затупи', 1)]\n",
      "[('заповедала', 1)]\n",
      "[('поднимающемуся', 1)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(radius*2):\n",
    "\tword_data = words_data[words_to_ids['на']].toarray()\n",
    "\tword_data_ord = word_data[i]\n",
    "\tword_params = [(ids_to_words[ii], x) for ii, x in enumerate(word_data_ord) if x > 0]\n",
    "\tprint(sorted(word_params, key=lambda x: x[1], reverse=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
